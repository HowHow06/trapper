version: "3.3"

volumes:
  data:

services:
  db:
    image: mariadb
    restart: always
    environment:
      MYSQL_ROOT_PASSWORD: ${MARIADB_ROOT_PASSWORD}
      MYSQL_DATABASE: ${MARIADB_DATABASE}
      MYSQL_USER: ${MARIADB_USER}
      MYSQL_PASSWORD: ${MARIADB_PASSWORD}
    volumes:
      - data:/var/lib/mysql
    ports:
      - 3306:3306

  extension-app-dev:
    image: "extension-app-image" # just image name
    build:
      context: .
      dockerfile: ./.docker/extension-vite/Dockerfile
    volumes:
      - ./extension-vite:/app
      - /app/node_modules # create a volume, so no need to reinstall the node modules
    ports:
      - ${VITE_DEV_PORT}:5000
    environment:
      - CHOKIDAR_USEPOLLING=true
    env_file:
      - ./.env
    profiles: # this service will only run when I specify the profile, `docker compose --profile dev up`
      - dev

  queue:
    image: "queue-image" # just image name
    env_file:
      - ./.env
    build:
      context: ./.docker/queue # will use this directory, and find Dockerfile there
    ports:
      - "5672:5672" # RabbitMQ
      - "15672:15672" # management interface
    environment:
      RABBITMQ_DEFAULT_USER: ${RABBITMQ_USER}
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_PASS}
      RABBITMQ_DEFAULT_VHOST: "/"
    command: ${RABBITMQ_ADMIN_USER} ${RABBITMQ_ADMIN_PASS} # pass this to entrypoint script to create admin account

  flower:
    image: mher/flower
    depends_on:
      - queue
    env_file:
      - ./.env
    command: [
        "celery",
        "flower",
        "--broker_api=http://${RABBITMQ_USER}:${RABBITMQ_PASS}@queue:15672/api//",
      ] # the `@queue` here is network of queue service, cannot use @localhost in docker container
    environment:
      - CELERY_BROKER_URL=amqp://${RABBITMQ_USER}:${RABBITMQ_PASS}@queue:5672//
    ports:
      - 5555:5555
    profiles: # this service will only run when I specify the profile, `docker compose --profile dev up`
      - dev

  celery-worker:
    image: "celery-worker-image" # just image name
    depends_on:
      - db
      - queue
    build:
      context: .
      dockerfile: ./.docker/celery-worker/Dockerfile
    volumes:
      - ./backend:/app
    env_file:
      - ./.env
    environment:
      - CURRENT_ENVIRONMENT=DOCKER # to determine how to get the environment variables, refer to config.py
      - CELERY_BROKER_URL=amqp://${RABBITMQ_USER}:${RABBITMQ_PASS}@queue:5672 # need to explicitly set to `queue` instead of `localhost`
      - MARIADB_SERVER=db

  xsshunterexpress:
    build:
      context: .
      dockerfile: ./.docker/xsshunterexpress/Dockerfile
    env_file:
      - ./.env
    environment:
      - XSSHUNTER_DATABASE_HOST=db
      - XSSHUNTER_NODE_ENV=docker
      - XSSHUNTER_SCREENSHOTS_DIR=/app/payload-fire-images
    ports:
      - "${XSSHUNTER_PORT}:55000"
    volumes:
      # Stores the SSL/TLS certificates and keys
      # in the "ssldata" directory.
      # Your certificates are automatically renewed
      # via LetsEncrypt, no extra work needed!
      - ./ssldata:/app/greenlock.d
      # Directory where payload fire images are stored.
      - ./payload-fire-images:/app/payload-fire-images
    # Comment out if you're using an external SQL
    # server and have commented out the DB section.

  backend:
    image: "backend-image" # just image name
    depends_on:
      - db
      - queue
      - celery-worker
    build:
      context: .
      dockerfile: ./.docker/backend/Dockerfile
    volumes:
      - ./backend:/app
    env_file:
      - ./.env
    ports:
      - 8000:8000
    environment:
      - ENVIRONMENT=PROD
      - CURRENT_ENVIRONMENT=DOCKER # to determine how to get the environment variables, refer to config.py
      - CELERY_BROKER_URL=amqp://${RABBITMQ_USER}:${RABBITMQ_PASS}@queue:5672 # need to explicitly set to `queue` instead of `localhost`
      - MARIADB_SERVER=db
